<?xml version="1.0" encoding="UTF-8"?>
<project version="4">
  <component name="CopilotDiffPersistence">
    <option name="pendingDiffs">
      <map>
        <entry key="$PROJECT_DIR$/BUILD_READY.md">
          <value>
            <PendingDiffInfo>
              <option name="filePath" value="$PROJECT_DIR$/BUILD_READY.md" />
              <option name="updatedContent" value="# ✅ BUILD FIX APPLIED - READY TO BUILD&#10;&#10;## Issue Fixed&#10;&#10;**Problem:** Missing import for `DebugConfig` in `ExerciseManager.kt`&#10;&#10;**Error Messages:**&#10;```&#10;e: Unresolved reference: DebugConfig (multiple locations)&#10;```&#10;&#10;**Solution Applied:**&#10;Added import statement:&#10;```kotlin&#10;import com.google.mediapipe.examples.poselandmarker.DebugConfig&#10;```&#10;&#10;---&#10;&#10;## Build Status&#10;&#10;✅ **COMPILATION ERRORS:** 0  &#10;⚠️ **WARNINGS:** Only minor code style warnings (severity 300)  &#10;✅ **ALL FILES COMPILE SUCCESSFULLY**&#10;&#10;---&#10;&#10;## Files Verified&#10;&#10;✅ `ExerciseManager.kt` - Fixed (import added)  &#10;✅ `SquatExercise.kt` - No errors  &#10;✅ `PoseProcessor.kt` - No errors  &#10;✅ `BaseExercise.kt` - No errors  &#10;✅ `PoseLandmarkerHelper.kt` - No errors  &#10;✅ `CameraFragment.kt` - No errors  &#10;&#10;---&#10;&#10;## Ready to Build&#10;&#10;```bash&#10;cd &quot;C:\Users\borhe\OneDrive\Documents\1pfe\test sport activity\mediapipe-samples-main\examples\pose_landmarker\android&quot;&#10;&#10;# Clean build&#10;gradlew.bat clean&#10;&#10;# Build APK&#10;gradlew.bat assembleDebug&#10;&#10;# Install on device&#10;gradlew.bat installDebug&#10;```&#10;&#10;---&#10;&#10;## What's Ready to Test&#10;&#10;### Game-Mode Balanced Squat Counter&#10;- ✅ Simplified state machine (READY → DOWN → BOTTOM → UP)&#10;- ✅ Hysteresis on BOTTOM phase (prevents jitter)&#10;- ✅ No blocking conditions (works sideways, at distance)&#10;- ✅ Angle validation (filters occlusion spikes)&#10;- ✅ 700ms cooldown (prevents double counting)&#10;&#10;### Test It&#10;1. Build and install app&#10;2. Stand in front of camera (front-facing)&#10;3. Perform ONE squat&#10;4. **Expected:** Counter shows &quot;Air Squat: 1&quot;&#10;5. **Log:** &quot;SQUAT ✔ Count = 1&quot;&#10;&#10;---&#10;&#10;## Next Steps&#10;&#10;1. **Build the app** (commands above)&#10;2. **Test on device** (perform squats)&#10;3. **Check logs** if needed:&#10;   ```bash&#10;   adb logcat | findstr /i &quot;SQUAT STATE COUNT&quot;&#10;   ```&#10;&#10;---&#10;&#10;## Documentation Available&#10;&#10;- **GAME_MODE_IMPLEMENTATION.md** - Full implementation details&#10;- **QUICK_TEST_GUIDE.md** - Testing procedures&#10;- **IMPLEMENTATION_SUMMARY.md** - Overview&#10;- **VISUAL_GUIDE.md** - Visual diagrams&#10;&#10;---&#10;&#10;**Status:** ✅ READY TO BUILD AND TEST  &#10;**Date:** January 30, 2026  &#10;**Build Errors:** 0  &#10;**Action Required:** Build and test on device&#10;" />
            </PendingDiffInfo>
          </value>
        </entry>
        <entry key="$PROJECT_DIR$/JUMPING_JACK_IMPLEMENTATION.md">
          <value>
            <PendingDiffInfo>
              <option name="filePath" value="$PROJECT_DIR$/JUMPING_JACK_IMPLEMENTATION.md" />
              <option name="updatedContent" value="# ✅ Jumping Jack Exercise Implementation - COMPLETE&#10;&#10;## Summary&#10;&#10;Jumping Jack exercise detection has been added to the MediaPipe Pose Android project following the exact specifications.&#10;&#10;---&#10;&#10;## Files Modified&#10;&#10;### 1. JumpingJackExercise.kt (REPLACED)&#10;**Path:** `app/src/main/java/.../exercises/jumpingjack/JumpingJackExercise.kt`&#10;&#10;**Implementation:**&#10;- Two-state machine: `CLOSED` ↔ `OPEN`&#10;- Arm angle detection: HIP → SHOULDER → WRIST (left side)&#10;- Leg spread detection: normalized ankle horizontal distance&#10;- 500ms cooldown to prevent double counting&#10;&#10;### 2. CameraFragment.kt (UPDATED)&#10;**Path:** `app/src/main/java/.../fragment/CameraFragment.kt`&#10;&#10;**Changes:**&#10;- Added `JumpingJackExercise` import&#10;- Updated `onRepCountUpdated()` to show dynamic exercise name&#10;- Updated `onExerciseChanged()` to show dynamic exercise name with toast&#10;- Added exercise switching buttons in `initExerciseSwitcher()`&#10;&#10;### 3. fragment_camera.xml (UPDATED)&#10;**Path:** `app/src/main/res/layout/fragment_camera.xml`&#10;&#10;**Changes:**&#10;- Added exercise selector buttons at top of screen&#10;- &quot;Air Squat&quot; button (green)&#10;- &quot;Jumping Jack&quot; button (blue)&#10;&#10;---&#10;&#10;## Detection Logic&#10;&#10;### State Machine&#10;```&#10;CLOSED → OPEN → CLOSED (count rep)&#10;```&#10;&#10;### Thresholds&#10;&#10;| Parameter | Value | Description |&#10;|-----------|-------|-------------|&#10;| ARM_OPEN_ANGLE | 150° | Arms overhead |&#10;| ARM_CLOSED_ANGLE | 60° | Arms at sides |&#10;| LEGS_OPEN_RATIO | 0.7 | Legs spread apart |&#10;| LEGS_CLOSED_RATIO | 0.4 | Legs together |&#10;| COOLDOWN_MS | 500ms | Prevent double counting |&#10;| MIN_TORSO_LENGTH | 0.1 | Skip if body too small |&#10;&#10;### Arm Open Condition&#10;```&#10;armAngle &gt; 150° AND wrist.y &lt; shoulder.y&#10;```&#10;&#10;### Arm Closed Condition&#10;```&#10;armAngle &lt; 60°&#10;```&#10;&#10;### Legs Open Condition&#10;```&#10;normalizedSpread = abs(leftAnkle.x - rightAnkle.x) / torsoLength&#10;normalizedSpread &gt; 0.7&#10;```&#10;&#10;### Legs Closed Condition&#10;```&#10;normalizedSpread &lt; 0.4&#10;```&#10;&#10;---&#10;&#10;## UI Changes&#10;&#10;### Exercise Selector (Top of Screen)&#10;- **Air Squat** button (green) - switches to squat detection&#10;- **Jumping Jack** button (blue) - switches to jumping jack detection&#10;&#10;### Counter Display (Center)&#10;- Shows: `[Exercise Name]: [Count]`&#10;- Example: `Jumping Jack: 5`&#10;&#10;### Reset Button (Bottom)&#10;- Resets counter for current exercise&#10;- Does NOT change exercise selection&#10;&#10;---&#10;&#10;## How It Works&#10;&#10;1. **User taps &quot;Jumping Jack&quot; button**&#10;2. `ExerciseManager.setActiveExercise(JumpingJackExercise())` is called&#10;3. Counter resets to 0&#10;4. UI shows &quot;Jumping Jack: 0&quot;&#10;5. **User performs jumping jack:**&#10;   - Arms go up + legs spread → OPEN state&#10;   - Arms go down + legs together → CLOSED state → **COUNT REP**&#10;6. Counter increments&#10;&#10;---&#10;&#10;## Architecture Preserved&#10;&#10;✅ Did NOT modify:&#10;- PoseLandmarkerHelper.kt&#10;- PoseProcessor.kt&#10;- Camera pipeline&#10;- MediaPipe pipeline&#10;- Existing Squat logic&#10;- Callback interfaces&#10;&#10;---&#10;&#10;## Build &amp; Test&#10;&#10;```bash&#10;cd &quot;C:\Users\borhe\OneDrive\Documents\1pfe\test sport activity\mediapipe-samples-main\examples\pose_landmarker\android&quot;&#10;&#10;# Build&#10;gradlew.bat assembleDebug&#10;&#10;# Install&#10;gradlew.bat installDebug&#10;```&#10;&#10;---&#10;&#10;## Test Checklist&#10;&#10;- [ ] App opens with front camera&#10;- [ ] Default exercise is &quot;Air Squat&quot;&#10;- [ ] Tap &quot;Jumping Jack&quot; switches exercise&#10;- [ ] Counter shows &quot;Jumping Jack: 0&quot;&#10;- [ ] Perform jumping jack → counter increments&#10;- [ ] No double counting (cooldown works)&#10;- [ ] Switch back to &quot;Air Squat&quot; works&#10;- [ ] Squat counter still works correctly&#10;- [ ] Reset button resets current exercise only&#10;&#10;---&#10;&#10;**Status:** ✅ IMPLEMENTATION COMPLETE  &#10;**Ready for:** Device testing&#10;" />
            </PendingDiffInfo>
          </value>
        </entry>
        <entry key="$PROJECT_DIR$/TECHNICAL_CAPABILITY_REPORT.md">
          <value>
            <PendingDiffInfo>
              <option name="filePath" value="$PROJECT_DIR$/TECHNICAL_CAPABILITY_REPORT.md" />
              <option name="updatedContent" value="# Technical Capability Summary — Pose Landmark Time‑Series Event Detection&#10;&#10;**Context:** This document summarizes capabilities and implementation patterns from my MediaPipe Pose Landmarker exercise detection engine. It focuses on production-grade movement event detection from noisy landmark streams (normalized X/Y[/Z]) using signal processing + state machines.&#10;&#10;---&#10;&#10;## 1) Architecture Overview&#10;&#10;### High-level pipeline&#10;The system is structured as a clean pipeline where **pose acquisition** is isolated from **event logic**:&#10;&#10;1. **Pose inference wrapper**: `PoseLandmarkerHelper.kt`&#10;   - Runs MediaPipe Tasks API (live stream) on camera frames.&#10;   - Emits `PoseLandmarkerResult` via callback.&#10;   - Keeps inference concerns (GPU/CPU delegate, model selection, frame rotation/mirroring) out of exercise logic.&#10;&#10;2. **Pose data model + geometry utilities**: `models/NormalizedPose.kt`&#10;   - Normalizes access to landmarks through a stable map type.&#10;   - Provides utilities for **distance** and **joint angle** calculation.&#10;   - Keeps exercise logic independent of MediaPipe SDK surface types.&#10;&#10;3. **MediaPipe → engine adapter**: `core/PoseProcessor.kt`&#10;   - Converts `PoseLandmarkerResult` into `NormalizedPose` (timestamped).&#10;   - (Optionally) computes a pose quality score.&#10;   - Design intent: keep detection logic agnostic to upstream pose provider.&#10;&#10;4. **Exercise/event routing**: `core/ExerciseManager.kt`&#10;   - Owns the **active exercise**.&#10;   - Forwards each pose frame to `activeExercise.processPose(pose)`.&#10;   - Forwards rep/state events to UI via a listener.&#10;&#10;5. **Per-exercise detection modules** (examples in repo):&#10;   - `exercises/squat/SquatExercise.kt` (squat rep detection)&#10;   - `exercises/jumpingjack/JumpingJackExercise.kt` (jumping jack detection)&#10;   - `exercises/sumohighpull/SumoHighPullExercise.kt` (sumo high pull detection)&#10;&#10;### State-machine-first event logic&#10;Each movement detector is implemented as:&#10;- a small **finite state machine (FSM)** (2–4 phases)&#10;- explicit, readable **transition rules**&#10;- rep counting only on a specific terminal transition&#10;- cooldown/debounce to prevent duplicate detections&#10;&#10;This design maps well to phase segmentation requirements (READY/DOWN/BOTTOM/UP, GROUND/AIR/LAND, etc.).&#10;&#10;---&#10;&#10;## 2) Signal Processing Strategy&#10;&#10;The engine operates on real-world noisy pose landmarks (normalized coordinates). The strategy is pragmatic and mobile-friendly:&#10;&#10;### A) Low-cost smoothing (EMA / moving average)&#10;For high-FPS streams, lightweight smoothing is usually enough:&#10;- **EMA (Exponential Moving Average)** for continuous signals (e.g., ankleY, hipY, knee angle):&#10;  - `s[t] = α * x[t] + (1-α) * s[t-1]`&#10;  - Typical `α` in 0.2–0.4 depending on FPS and jitter.&#10;- **Short moving average** (3–5 frames) for derived features when EMA isn’t suitable.&#10;&#10;Goal: reduce frame jitter without adding latency or heavy computation.&#10;&#10;### B) Derivatives for motion cues (velocity/acceleration)&#10;For event detection (e.g., jumping), velocity improves robustness:&#10;- `v[t] = (y[t] - y[t-1]) / dt`&#10;- optional acceleration: `a[t] = (v[t] - v[t-1]) / dt`&#10;&#10;This helps differentiate:&#10;- genuine takeoff vs. noisy spikes&#10;- landing bounce vs. a new jump&#10;&#10;### C) Hysteresis by design (not a single threshold)&#10;To prevent “state bouncing” near thresholds, transitions use **separate enter/exit thresholds**:&#10;- Enter AIR when signal crosses “strong” threshold&#10;- Exit AIR only when it crosses a different “return” threshold&#10;&#10;This is used in the exercise modules (e.g., open vs closed thresholds; down vs up angles).&#10;&#10;---&#10;&#10;## 3) Event Detection Design (Phase Segmentation + Anti-Double-Count)&#10;&#10;### Core pattern&#10;1. **Extract features** per frame&#10;   - joint angles (e.g., hip-knee-ankle)&#10;   - normalized distances (e.g., ankle spread / torso length)&#10;   - position signals (e.g., ankleY)&#10;&#10;2. **Validate** frame (cheap checks)&#10;   - missing landmark(s) → skip frame&#10;   - out-of-range computed angles → ignore frame (common occlusion spike handling)&#10;&#10;3. **Update state machine**&#10;   - transitions only when conditions are stable and meaningful&#10;&#10;4. **Count rep** only on one terminal transition&#10;   - plus cooldown/debounce window&#10;&#10;### Cooldown / debouncing (duplicate prevention)&#10;Duplicate counts often happen due to multi-peak motion (bounce) or threshold overlap.&#10;A production approach:&#10;- Store `lastEventTime`.&#10;- Only count if `now - lastEventTime &gt;= cooldownMs`.&#10;- Cooldown is paired with hysteresis so the FSM cannot re-trigger on the same movement peak.&#10;&#10;---&#10;&#10;## 4) Jump Detection Approach (Ankle Y) — Preventing Double Counts&#10;&#10;This is a robust “jump-like” detector based on ankle Y time series, suitable for Python/TypeScript implementation.&#10;&#10;### Input signal&#10;- Use **normalized Y** from pose landmarks.&#10;- Build a stable ankle height signal:&#10;  - `ankleY = mean(leftAnkle.y, rightAnkle.y)` if both available&#10;  - else use the available ankle with the best visibility/confidence&#10;&#10;&gt; Note: In MediaPipe normalized coordinates, Y typically increases downward. The logic below assumes you pick a consistent sign convention (e.g., use `height = 1 - ankleY` so “up” increases height).&#10;&#10;### Step 1 — Baseline normalization (distance + drift tolerance)&#10;Maintain a slowly-updating standing baseline:&#10;- `baseline = EMA(ankleHeight, αSlow)` where `αSlow` is small (e.g., 0.02–0.05)&#10;- Compute displacement: `d = ankleHeight - baseline`&#10;&#10;This compensates for:&#10;- kids moving closer/farther&#10;- slight camera pitch changes&#10;- gradual posture drift&#10;&#10;### Step 2 — Smoothing&#10;Apply a faster EMA for event logic:&#10;- `h = EMA(d, αFast)` (e.g., 0.25–0.35)&#10;&#10;### Step 3 — Velocity/acceleration estimates&#10;Compute velocity using timestamps to handle FPS variance:&#10;- `dt = (t - tPrev)` (seconds)&#10;- `v = (h - hPrev) / dt`&#10;&#10;### Step 4 — Phased state machine with hysteresis&#10;Use a 3-phase FSM:&#10;&#10;**States:** `GROUND → AIR → LANDING → GROUND` (LANDING can be merged into AIR if you want simpler)&#10;&#10;**Key thresholds (example, tuned per data):**&#10;- `TAKEOFF_V_ENTER` : minimum upward velocity to start a jump&#10;- `TAKEOFF_H_ENTER` : minimum displacement above baseline to confirm takeoff&#10;- `LAND_H_EXIT` : displacement threshold to confirm landing return (smaller than enter)&#10;&#10;**Transitions:**&#10;- **GROUND → AIR** when:&#10;  - `v &gt; TAKEOFF_V_ENTER` **AND** `h &gt; TAKEOFF_H_ENTER`&#10;  - (optional) require condition to persist for N frames or N ms&#10;&#10;- **AIR → LANDING** when:&#10;  - velocity changes sign (peak passed) **OR** `v &lt; 0` for a short duration&#10;&#10;- **LANDING → GROUND** when:&#10;  - `h &lt; LAND_H_EXIT` for a small window (e.g., 2–3 frames)&#10;&#10;### Step 5 — Double-count prevention (multi-peak landing bounce)&#10;Multi-peak landing bounce usually looks like: `AIR → small dip → second dip`.&#10;Prevent duplicates via:&#10;&#10;1) **Cooldown window**&#10;- Count the jump once when entering `GROUND` (LANDING→GROUND), but only if:&#10;  - `now - lastJumpTime &gt;= cooldownMs` (e.g., 400–800 ms)&#10;&#10;2) **Re-arm condition**&#10;- The detector must see a stable GROUND condition (`h` near baseline) before it can takeoff again.&#10;&#10;### Edge-case handling&#10;- **Missing landmarks**: skip update; don’t reset FSM unless missing persists for a long timeout.&#10;- **Occlusion spikes**: clamp or ignore if `|h|` exceeds plausible biomechanical range.&#10;- **FPS variance**: compute `dt` from timestamps; cap dt if needed to avoid huge derivative spikes.&#10;&#10;---&#10;&#10;## 5) Robustness &amp; Edge Case Handling&#10;&#10;### Noisy, real-world landmark data&#10;Practical failure modes and mitigations:&#10;- **Threshold jitter** → hysteresis thresholds + short stability windows&#10;- **Multi-peak motion** → FSM + cooldown + re-arm condition&#10;- **Occlusion spikes** → range checks + skip invalid frames (don’t “teleport” state)&#10;- **Partial body in frame** → fail-soft policy (skip frames, preserve state)&#10;&#10;### Clean separation of concerns&#10;The pipeline is organized so you can:&#10;- swap pose provider (MediaPipe/OpenPose/custom) by re-implementing PoseProcessor&#10;- keep event logic unchanged because it depends only on normalized landmark data&#10;&#10;---&#10;&#10;## 6) Production Readiness&#10;&#10;### Performance (real-time)&#10;- Constant-time features per frame: a few distances/angles + simple arithmetic.&#10;- No heavy filtering or optimization loops.&#10;- Logging can be rate-limited (e.g., once/sec) to avoid throughput impact.&#10;&#10;### Deterministic and testable logic&#10;The FSM-based approach is deterministic and can be tested offline:&#10;- record landmark JSON per frame&#10;- replay through detectors&#10;- compare expected events vs detected events&#10;&#10;---&#10;&#10;## 7) Optional Enhancements (Low-risk, High-value)&#10;&#10;1) **Confidence score per event**&#10;- Combine feature margins (how far past thresholds), signal stability, and landmark visibility.&#10;&#10;2) **Structured event output contract**&#10;Example:&#10;```json&#10;{&#10;  &quot;type&quot;: &quot;jump&quot;,&#10;  &quot;startTs&quot;: 123456789,&#10;  &quot;peakTs&quot;: 123456920,&#10;  &quot;endTs&quot;: 123457050,&#10;  &quot;repIndex&quot;: 12,&#10;  &quot;confidence&quot;: 0.86,&#10;  &quot;features&quot;: {&#10;    &quot;takeoffV&quot;: 0.42,&#10;    &quot;peakHeight&quot;: 0.18,&#10;    &quot;flightTimeMs&quot;: 280&#10;  }&#10;}&#10;```&#10;&#10;3) **Config-driven thresholds**&#10;- Keep constants in a config object for fast tuning per population (kids/adults) and camera setups.&#10;&#10;4) **Offline validation harness**&#10;- CLI tool (Python or Node) to:&#10;  - load recorded landmarks&#10;  - run detector&#10;  - output events + diagnostics (plots optional)&#10;&#10;5) **Performance monitoring hooks**&#10;- lightweight timers (per stage) + counters for dropped frames / invalid frames.&#10;&#10;---&#10;&#10;## Relevant Code Footprint (from my engine)&#10;- Pipeline wrapper: `app/src/main/java/.../PoseLandmarkerHelper.kt`&#10;- Adapter/model: `core/PoseProcessor.kt`, `models/NormalizedPose.kt`&#10;- Routing: `core/ExerciseManager.kt`&#10;- Detectors (FSM + cooldown patterns):&#10;  - `exercises/jumpingjack/JumpingJackExercise.kt`&#10;  - `exercises/sumohighpull/SumoHighPullExercise.kt`&#10;  - `exercises/squat/SquatExercise.kt`&#10;" />
            </PendingDiffInfo>
          </value>
        </entry>
        <entry key="$PROJECT_DIR$/UPWORK_COVER_LETTER.md">
          <value>
            <PendingDiffInfo>
              <option name="filePath" value="$PROJECT_DIR$/UPWORK_COVER_LETTER.md" />
              <option name="updatedContent" value="# Upwork Proposal — Pose Landmark Time‑Series Event Detection (MediaPipe‑style)&#10;&#10;Hi! I’m a mobile + applied CV engineer and I’ve built a real‑time pose‑driven exercise engine on top of **MediaPipe Pose Landmarker** that turns noisy landmark streams into **clean rep events** using state machines, hysteresis, and cooldown/debouncing.&#10;&#10;## Why I’m a fit for your job&#10;From your description, you need someone who can:&#10;- segment motion phases from noisy landmark time‑series&#10;- prevent duplicate detections from multi‑peak motion&#10;- use smoothing / hysteresis / velocity thinking&#10;- ship production‑ready logic in TypeScript or Python&#10;&#10;That’s exactly what I’ve been doing in my MediaPipe Pose project:&#10;&#10;### What I’ve built (relevant parts)&#10;- **Clean separation of pipeline vs logic**&#10;  - CameraX/MediaPipe inference is isolated in `PoseLandmarkerHelper.kt`.&#10;  - MediaPipe results are converted into a platform‑agnostic model `NormalizedPose` in `core/PoseProcessor.kt`.&#10;  - Exercise/event logic runs in dedicated modules extending `BaseExercise` and receives **only normalized coordinates** (not MediaPipe types).&#10;&#10;- **Robust event detection patterns** (rep counting)&#10;  - Multi‑phase squat detector (`exercises/squat/SquatExercise.kt`) using:&#10;    - knee angle (Hip–Knee–Ankle)&#10;    - explicit phase machine (READY → DOWN → BOTTOM → UP)&#10;    - **hysteresis thresholds** (different enter/exit angles)&#10;    - **cooldown** to stop double/triple counts&#10;    - frame skipping on out‑of‑range angles to handle occlusion spikes&#10;  - Jumping‑jack detector (`exercises/jumpingjack/JumpingJackExercise.kt`) using:&#10;    - torso‑normalized leg spread + arm angle&#10;    - two‑state machine (OPEN/CLOSED)&#10;    - cooldown + “don’t reset on missing landmarks” stability rule&#10;&#10;- **Real‑time performance constraints**&#10;  - All math is constant‑time per frame (simple geometry, no heavy filters), designed to keep FPS stable.&#10;  - Logging is rate‑limited (e.g., once/sec) for debugging without harming throughput.&#10;&#10;## How I’d detect a jump from ankle Y (and prevent double counts)&#10;I’d treat it as a **time‑series event segmentation** problem:&#10;1) Build a stable signal from landmarks:&#10;   - use **average ankle Y** (left+right)/2 or choose the more confident ankle&#10;   - subtract a slowly varying baseline (standing height) to handle camera tilt/distance drift&#10;2) Smooth lightly (EMA or small moving average) to reduce jitter.&#10;3) Derive velocity:&#10;   - `v = y[t] - y[t-1]` (optionally scaled by dt)&#10;4) Use a small state machine + hysteresis:&#10;   - **GROUND** → **TAKEOFF** when upward velocity crosses a threshold and displacement exceeds `enter` threshold&#10;   - **AIR** until velocity changes sign and we pass `exit` threshold&#10;   - count jump **once** on AIR → GROUND (or on detected landing peak)&#10;5) Add **debounce/cooldown** (e.g., 300–600ms) so multi‑peak landings don’t create duplicates.&#10;&#10;This handles:&#10;- multiple local peaks from bouncing&#10;- noisy landmarks&#10;- different jump heights / kids movement&#10;&#10;## Project link (attach)&#10;If you’d like, I can share:&#10;- a GitHub link to this exact repo (MediaPipe Pose Landmarker Android sample extended into a modular “exercise engine”), or&#10;- a small extracted TypeScript/Python implementation of the same event‑segmentation logic for your web pipeline.&#10;&#10;## What I’d do first on your project&#10;- Inspect your raw landmark streams and define the **primary signals** per event (ankle Y, hip Y, COM proxy).&#10;- Add a clean event contract: `{eventType, startTs, peakTs, endTs, confidence, features}`.&#10;- Implement a **phase machine + hysteresis + cooldown** per event.&#10;- Validate on edge cases: partial body, occlusion spikes, view angle changes, variable FPS.&#10;&#10;If you share a sample JSON/CSV of landmarks (even 10–30 seconds), I can propose concrete thresholds and a first working detector quickly.&#10;" />
            </PendingDiffInfo>
          </value>
        </entry>
        <entry key="$PROJECT_DIR$/app/src/main/java/com/google/mediapipe/examples/poselandmarker/DebugConfig.kt">
          <value>
            <PendingDiffInfo>
              <option name="filePath" value="$PROJECT_DIR$/app/src/main/java/com/google/mediapipe/examples/poselandmarker/DebugConfig.kt" />
              <option name="updatedContent" value="package com.google.mediapipe.examples.poselandmarker&#10;&#10;/**&#10; * Debug configuration for squat counter troubleshooting.&#10; * &#10; * USAGE:&#10; * Set DEBUG_MODE = true to enable all debug logging.&#10; * Set DEBUG_MODE = false for production (removes log overhead).&#10; * &#10; * LOG TAGS:&#10; * - PIPELINE: Camera + MediaPipe flow&#10; * - SQUAT: Squat detection logic&#10; * - STATE: Phase state transitions&#10; * - COUNT: Rep counting events&#10; * - CALLBACK: UI callback events&#10; */&#10;object DebugConfig {&#10;    &#10;    /**&#10;     * Master debug switch.&#10;     * Turn this ON when debugging squat counter issues.&#10;     * Turn this OFF for production builds.&#10;     */&#10;    const val DEBUG_MODE = true&#10;    &#10;    /**&#10;     * Log every frame (warning: very verbose!)&#10;     * Only enable for short debug sessions.&#10;     */&#10;    const val LOG_EVERY_FRAME = false&#10;    &#10;    /**&#10;     * Log validation details (facingCamera, armsForward, etc.)&#10;     */&#10;    const val LOG_VALIDATION = true&#10;    &#10;    /**&#10;     * Log angle calculations&#10;     */&#10;    const val LOG_ANGLES = true&#10;    &#10;    /**&#10;     * Log state machine transitions&#10;     */&#10;    const val LOG_STATE_TRANSITIONS = true&#10;    &#10;    /**&#10;     * Log callback execution&#10;     */&#10;    const val LOG_CALLBACKS = true&#10;    &#10;    /**&#10;     * Log pose processor validation&#10;     */&#10;    const val LOG_POSE_VALIDATION = true&#10;    &#10;    // Log tag constants&#10;    const val TAG_PIPELINE = &quot;PIPELINE&quot;&#10;    const val TAG_SQUAT = &quot;SQUAT&quot;&#10;    const val TAG_STATE = &quot;STATE&quot;&#10;    const val TAG_COUNT = &quot;COUNT&quot;&#10;    const val TAG_CALLBACK = &quot;CALLBACK&quot;&#10;}&#10;" />
            </PendingDiffInfo>
          </value>
        </entry>
        <entry key="$PROJECT_DIR$/app/src/main/java/com/google/mediapipe/examples/poselandmarker/core/PoseProcessor.kt">
          <value>
            <PendingDiffInfo>
              <option name="filePath" value="$PROJECT_DIR$/app/src/main/java/com/google/mediapipe/examples/poselandmarker/core/PoseProcessor.kt" />
              <option name="originalContent" value="&#10;" />
              <option name="updatedContent" value="package com.google.mediapipe.examples.poselandmarker.core&#10;&#10;import android.util.Log&#10;import com.google.mediapipe.examples.poselandmarker.DebugConfig&#10;import com.google.mediapipe.examples.poselandmarker.models.NormalizedPose&#10;import com.google.mediapipe.examples.poselandmarker.models.PoseLandmark&#10;import com.google.mediapipe.tasks.vision.poselandmarker.PoseLandmarkerResult&#10;&#10;/**&#10; * PoseProcessor - Converts MediaPipe results into normalized pose data.&#10; *&#10; * RESPONSIBILITIES:&#10; * - Extract landmarks from PoseLandmarkerResult&#10; * - Create NormalizedPose data model&#10; * - Validate pose quality (visibility, completeness)&#10; * - Abstract MediaPipe internals from exercise logic&#10; *&#10; * ARCHITECTURE:&#10; * This is the BRIDGE between MediaPipe SDK and your exercise engine.&#10; * Exercise logic should NEVER directly access MediaPipe types.&#10; *&#10; * FUTURE CROSS-PLATFORM:&#10; * - Flutter: Custom pose data from ML Kit or TensorFlow Lite&#10; * - Unity: Custom pose data from Barracuda or native plugins&#10; * - All platforms convert to NormalizedPose format&#10; */&#10;object PoseProcessor {&#10;&#10;    private const val TAG = &quot;PoseProcessor&quot;&#10;    private var lastLogTime = 0L&#10;&#10;    /**&#10;     * Convert MediaPipe PoseLandmarkerResult to NormalizedPose.&#10;     *&#10;     * @param result MediaPipe detection result&#10;     * @return NormalizedPose or null if invalid&#10;     */&#10;    fun processResult(result: PoseLandmarkerResult): NormalizedPose? {&#10;        if (result.landmarks().isEmpty()) {&#10;            return null&#10;        }&#10;&#10;        val landmarks = result.landmarks()[0]&#10;&#10;        // Build landmark map - include ALL landmarks regardless of visibility&#10;        // Let the exercise logic decide what's needed&#10;        val landmarkMap = mutableMapOf&lt;PoseLandmark, com.google.mediapipe.tasks.components.containers.NormalizedLandmark&gt;()&#10;&#10;        PoseLandmark.values().forEach { poseLandmark -&gt;&#10;            if (poseLandmark.index &lt; landmarks.size) {&#10;                landmarkMap[poseLandmark] = landmarks[poseLandmark.index]&#10;            }&#10;        }&#10;&#10;        // NO VALIDATION - just return the pose&#10;        // SquatExercise will handle missing landmarks gracefully&#10;        return NormalizedPose(&#10;            landmarks = landmarkMap,&#10;            timestamp = result.timestampMs()&#10;        )&#10;    }&#10;&#10;    /**&#10;     * Check if pose has all required landmarks for exercise detection.&#10;     *&#10;     * REQUIRED LANDMARKS (STRICT - must be visible):&#10;     * - Shoulders (LEFT, RIGHT)&#10;     * - Hips (LEFT, RIGHT)&#10;     * - Knees (LEFT, RIGHT)&#10;     * - Ankles (LEFT, RIGHT)&#10;     *&#10;     * OPTIONAL LANDMARKS (nice to have but not required):&#10;     * - Wrists (LEFT, RIGHT) - may not always be visible&#10;     */&#10;    private fun isPoseComplete(landmarks: Map&lt;PoseLandmark, com.google.mediapipe.tasks.components.containers.NormalizedLandmark&gt;): Boolean {&#10;        // Core body landmarks - MUST be visible&#10;        val requiredLandmarks = listOf(&#10;            PoseLandmark.LEFT_SHOULDER,&#10;            PoseLandmark.RIGHT_SHOULDER,&#10;            PoseLandmark.LEFT_HIP,&#10;            PoseLandmark.RIGHT_HIP,&#10;            PoseLandmark.LEFT_KNEE,&#10;            PoseLandmark.RIGHT_KNEE,&#10;            PoseLandmark.LEFT_ANKLE,&#10;            PoseLandmark.RIGHT_ANKLE&#10;        )&#10;&#10;        // Check all required landmarks exist and are visible&#10;        // Lower visibility threshold from 0.5 to 0.3 for more lenient detection&#10;        return requiredLandmarks.all { landmark -&gt;&#10;            val lm = landmarks[landmark]&#10;            lm != null &amp;&amp; lm.visibility().orElse(0f) &gt; 0.3f&#10;        }&#10;    }&#10;&#10;    /**&#10;     * Get pose quality score (0.0 - 1.0).&#10;     * Based on average visibility of key landmarks.&#10;     *&#10;     * Used for UI feedback:&#10;     * - &lt; 0.5: &quot;Move closer to camera&quot;&#10;     * - 0.5-0.7: &quot;Pose partially visible&quot;&#10;     * - &gt; 0.7: &quot;Good pose quality&quot;&#10;     */&#10;    fun getPoseQuality(pose: NormalizedPose): Float {&#10;        val keyLandmarks = listOf(&#10;            PoseLandmark.LEFT_SHOULDER,&#10;            PoseLandmark.RIGHT_SHOULDER,&#10;            PoseLandmark.LEFT_HIP,&#10;            PoseLandmark.RIGHT_HIP,&#10;            PoseLandmark.LEFT_KNEE,&#10;            PoseLandmark.RIGHT_KNEE&#10;        )&#10;&#10;        val visibilities = keyLandmarks.mapNotNull { landmark -&gt;&#10;            pose.getLandmark(landmark)?.visibility()?.orElse(0f)&#10;        }&#10;&#10;        return if (visibilities.isEmpty()) {&#10;            0f&#10;        } else {&#10;            visibilities.average().toFloat()&#10;        }&#10;    }&#10;}&#10;&#10;" />
            </PendingDiffInfo>
          </value>
        </entry>
        <entry key="$PROJECT_DIR$/app/src/main/java/com/google/mediapipe/examples/poselandmarker/exercises/base/BaseExercise.kt">
          <value>
            <PendingDiffInfo>
              <option name="filePath" value="$PROJECT_DIR$/app/src/main/java/com/google/mediapipe/examples/poselandmarker/exercises/base/BaseExercise.kt" />
              <option name="originalContent" value="&#10;" />
              <option name="updatedContent" value="package com.google.mediapipe.examples.poselandmarker.exercises.base&#10;&#10;import com.google.mediapipe.examples.poselandmarker.DebugConfig&#10;import com.google.mediapipe.examples.poselandmarker.models.NormalizedPose&#10;&#10;/**&#10; * Base interface for all exercise detection modules.&#10; *&#10; * ARCHITECTURE:&#10; * - Each exercise (Squat, JumpingJack, Jump, etc.) implements this interface&#10; * - ExerciseManager routes pose frames to the active exercise&#10; * - UI layer receives callbacks via ExerciseListener&#10; *&#10; * FUTURE CROSS-PLATFORM INTEGRATION:&#10; * - Flutter: Flutter app will communicate via platform channels&#10; * - Unity: Unity plugin will receive exercise events via JNI&#10; * - This interface remains the same across platforms&#10; */&#10;abstract class BaseExercise {&#10;&#10;    /**&#10;     * Exercise state for UI feedback and game logic.&#10;     */&#10;    enum class ExerciseState {&#10;        IDLE,           // No valid pose detected&#10;        READY,          // User in starting position&#10;        IN_PROGRESS,    // Mid-exercise (e.g., descending in squat)&#10;        COMPLETED       // Rep completed&#10;    }&#10;&#10;    /**&#10;     * Listener for exercise events (callbacks to UI layer).&#10;     */&#10;    interface ExerciseListener {&#10;        /**&#10;         * Called when rep count changes.&#10;         * @param count Total rep count&#10;         * @param exerciseName Name of the exercise&#10;         */&#10;        fun onRepCountUpdated(count: Int, exerciseName: String)&#10;&#10;        /**&#10;         * Called when exercise state changes.&#10;         * @param state New state&#10;         * @param details Optional state details (e.g., &quot;Squat depth: 90°&quot;)&#10;         */&#10;        fun onStateChanged(state: ExerciseState, details: String = &quot;&quot;)&#10;&#10;        /**&#10;         * Called when exercise validation fails.&#10;         * @param reason Why the rep was invalid (e.g., &quot;Arms not horizontal&quot;)&#10;         */&#10;        fun onValidationError(reason: String)&#10;&#10;        /**&#10;         * Called when exercise set is completed.&#10;         * @param totalReps Total reps completed&#10;         * @param duration Total duration in seconds&#10;         */&#10;        fun onExerciseComplete(totalReps: Int, duration: Long)&#10;    }&#10;&#10;    // ========== ABSTRACT METHODS (Must be implemented by each exercise) ==========&#10;&#10;    /**&#10;     * Process a pose frame and update exercise state.&#10;     * This is the main detection loop called by ExerciseManager.&#10;     *&#10;     * @param pose Normalized pose data&#10;     */&#10;    abstract fun processPose(pose: NormalizedPose)&#10;&#10;    /**&#10;     * Reset exercise state and rep count.&#10;     * Called when:&#10;     * - User switches exercises&#10;     * - User starts a new session&#10;     * - UI requests reset&#10;     */&#10;    abstract fun reset()&#10;&#10;    /**&#10;     * Get exercise name (e.g., &quot;Squat&quot;, &quot;Jumping Jack&quot;).&#10;     */&#10;    abstract fun getName(): String&#10;&#10;    /**&#10;     * Get exercise description for UI.&#10;     */&#10;    abstract fun getDescription(): String&#10;&#10;    /**&#10;     * Check if pose is valid for this exercise.&#10;     * Used for pre-start validation.&#10;     *&#10;     * @param pose Normalized pose data&#10;     * @return Pair&lt;Boolean, String&gt; (isValid, reason)&#10;     */&#10;    abstract fun isPoseValid(pose: NormalizedPose): Pair&lt;Boolean, String&gt;&#10;&#10;    // ========== SHARED STATE (Available to all exercises) ==========&#10;&#10;    // Use backing field to avoid conflicts&#10;    private var _repCount: Int = 0&#10;    private var _currentState: ExerciseState = ExerciseState.IDLE&#10;&#10;    /**&#10;     * Current rep count - readable by all, writable by subclasses only&#10;     */&#10;    var repCount: Int&#10;        get() = _repCount&#10;        protected set(value) { _repCount = value }&#10;&#10;    /**&#10;     * Current exercise state - readable by all, writable by subclasses only&#10;     */&#10;    var currentState: ExerciseState&#10;        get() = _currentState&#10;        protected set(value) { _currentState = value }&#10;&#10;    private var listener: ExerciseListener? = null&#10;    protected var startTime: Long = 0L&#10;&#10;    /**&#10;     * Set listener for exercise events.&#10;     */&#10;    fun setListener(listener: ExerciseListener?) {&#10;        this.listener = listener&#10;    }&#10;&#10;    /**&#10;     * Notify listener of rep count update.&#10;     */&#10;    protected fun notifyRepCountUpdated() {&#10;        // DEBUG: Log callback firing&#10;        if (DebugConfig.DEBUG_MODE &amp;&amp; DebugConfig.LOG_CALLBACKS) {&#10;            android.util.Log.d(DebugConfig.TAG_CALLBACK, &quot;notifyRepCountUpdated() called | &quot; +&#10;                &quot;count=$repCount | &quot; +&#10;                &quot;exercise=${getName()} | &quot; +&#10;                &quot;listener=${if (listener != null) &quot;SET&quot; else &quot;NULL&quot;}&quot;)&#10;        }&#10;        listener?.onRepCountUpdated(repCount, getName())&#10;    }&#10;&#10;    /**&#10;     * Notify listener of state change.&#10;     */&#10;    protected fun notifyStateChanged(details: String = &quot;&quot;) {&#10;        // DEBUG: Log state change callback&#10;        if (DebugConfig.DEBUG_MODE &amp;&amp; DebugConfig.LOG_CALLBACKS) {&#10;            android.util.Log.d(DebugConfig.TAG_CALLBACK, &quot;notifyStateChanged() | &quot; +&#10;                &quot;state=$currentState | &quot; +&#10;                &quot;details='$details'&quot;)&#10;        }&#10;        listener?.onStateChanged(currentState, details)&#10;    }&#10;&#10;    /**&#10;     * Notify listener of validation error.&#10;     */&#10;    protected fun notifyValidationError(reason: String) {&#10;        listener?.onValidationError(reason)&#10;    }&#10;&#10;    /**&#10;     * Notify listener of exercise completion.&#10;     */&#10;    protected fun notifyExerciseComplete() {&#10;        val duration = (System.currentTimeMillis() - startTime) / 1000&#10;        listener?.onExerciseComplete(repCount, duration)&#10;    }&#10;}&#10;&#10;" />
            </PendingDiffInfo>
          </value>
        </entry>
        <entry key="$PROJECT_DIR$/app/src/main/java/com/google/mediapipe/examples/poselandmarker/models/NormalizedPose.kt">
          <value>
            <PendingDiffInfo>
              <option name="filePath" value="$PROJECT_DIR$/app/src/main/java/com/google/mediapipe/examples/poselandmarker/models/NormalizedPose.kt" />
              <option name="updatedContent" value="package com.google.mediapipe.examples.poselandmarker.models&#10;&#10;import com.google.mediapipe.tasks.components.containers.NormalizedLandmark&#10;&#10;/**&#10; * Normalized pose data structure for exercise detection.&#10; * All coordinates are normalized (0.0 to 1.0) for distance independence.&#10; *&#10; * This model provides clean access to pose landmarks without MediaPipe dependencies&#10; * in exercise logic. Future integration with Flutter/Unity will use this structure.&#10; */&#10;data class NormalizedPose(&#10;    val landmarks: Map&lt;PoseLandmark, NormalizedLandmark&gt;,&#10;    val timestamp: Long&#10;) {&#10;    &#10;    /**&#10;     * Calculate angle between three points (in degrees).&#10;     * Used for joint angle calculations like knee, elbow, etc.&#10;     * &#10;     * @param pointA First point (e.g., Hip)&#10;     * @param vertex Middle point/vertex (e.g., Knee)&#10;     * @param pointC Third point (e.g., Ankle)&#10;     * @return Angle in degrees (0-180)&#10;     */&#10;    fun calculateAngle(&#10;        pointA: PoseLandmark,&#10;        vertex: PoseLandmark,&#10;        pointC: PoseLandmark&#10;    ): Float {&#10;        val a = landmarks[pointA] ?: return 0f&#10;        val b = landmarks[vertex] ?: return 0f&#10;        val c = landmarks[pointC] ?: return 0f&#10;        &#10;        val radians = Math.atan2((c.y() - b.y()).toDouble(), (c.x() - b.x()).toDouble()) -&#10;                Math.atan2((a.y() - b.y()).toDouble(), (a.x() - b.x()).toDouble())&#10;        var angle = Math.abs(radians * 180.0 / Math.PI)&#10;        if (angle &gt; 180.0) {&#10;            angle = 360.0 - angle&#10;        }&#10;        return angle.toFloat()&#10;    }&#10;    &#10;    /**&#10;     * Calculate Euclidean distance between two landmarks.&#10;     * Used for body measurements like torso length, shoulder width, etc.&#10;     */&#10;    fun calculateDistance(point1: PoseLandmark, point2: PoseLandmark): Float {&#10;        val p1 = landmarks[point1] ?: return 0f&#10;        val p2 = landmarks[point2] ?: return 0f&#10;        &#10;        return Math.sqrt(&#10;            Math.pow((p1.x() - p2.x()).toDouble(), 2.0) +&#10;            Math.pow((p1.y() - p2.y()).toDouble(), 2.0)&#10;        ).toFloat()&#10;    }&#10;    &#10;    /**&#10;     * Get landmark by enum (safe access).&#10;     */&#10;    fun getLandmark(landmark: PoseLandmark): NormalizedLandmark? {&#10;        return landmarks[landmark]&#10;    }&#10;}&#10;&#10;/**&#10; * MediaPipe Pose 33-point landmark model.&#10; * Enum provides type-safe access to pose landmarks.&#10; */&#10;enum class PoseLandmark(val index: Int) {&#10;    NOSE(0),&#10;    LEFT_EYE_INNER(1),&#10;    LEFT_EYE(2),&#10;    LEFT_EYE_OUTER(3),&#10;    RIGHT_EYE_INNER(4),&#10;    RIGHT_EYE(5),&#10;    RIGHT_EYE_OUTER(6),&#10;    LEFT_EAR(7),&#10;    RIGHT_EAR(8),&#10;    MOUTH_LEFT(9),&#10;    MOUTH_RIGHT(10),&#10;    LEFT_SHOULDER(11),&#10;    RIGHT_SHOULDER(12),&#10;    LEFT_ELBOW(13),&#10;    RIGHT_ELBOW(14),&#10;    LEFT_WRIST(15),&#10;    RIGHT_WRIST(16),&#10;    LEFT_PINKY(17),&#10;    RIGHT_PINKY(18),&#10;    LEFT_INDEX(19),&#10;    RIGHT_INDEX(20),&#10;    LEFT_THUMB(21),&#10;    RIGHT_THUMB(22),&#10;    LEFT_HIP(23),&#10;    RIGHT_HIP(24),&#10;    LEFT_KNEE(25),&#10;    RIGHT_KNEE(26),&#10;    LEFT_ANKLE(27),&#10;    RIGHT_ANKLE(28),&#10;    LEFT_HEEL(29),&#10;    RIGHT_HEEL(30),&#10;    LEFT_FOOT_INDEX(31),&#10;    RIGHT_FOOT_INDEX(32)&#10;}&#10;" />
            </PendingDiffInfo>
          </value>
        </entry>
      </map>
    </option>
  </component>
</project>